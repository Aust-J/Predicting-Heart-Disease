---
title: "Predicting heart disease with classification trees"
author: "Setsuka Aust"
output: html_document
---

<!-- change echo=FALSE to echo=TRUE to show code -->
```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```


```{r collapse=TRUE, warning=FALSE}
library(rpart)
library(rpart.plot)
library(maptree)
library(pROC)
library(PRROC)
# the following utility files can be found attached to the assignment
source("https://raw.githubusercontent.com/grbruns/cst383/master/lin-regr-util.R")
source("https://raw.githubusercontent.com/grbruns/cst383/master/class-util.R")
```

### Reading and preprocessing the data

The data set provided was gathered among heart disease researchers and medical institutes in an effort to utilize machine learning to predict contributing factors in heart disease. The information extracted from this can further improve understanding of the treatment and prevention of heart disease. There are 13 explanatory variables that relate to the one response variable (heart disease) 

Processing of the data was inspired by the example and done for clarity

```{r}
heart = read.table("https://raw.githubusercontent.com/grbruns/cst383/master/heart.dat", quote = "/")
names(heart) <- c("AGE", "SEX", "CHESTPAIN", "RESTBP", "CHOL",
                  "SUGAR", "ECG", "MAXHR", "ANGINA", "DEP", "EXERCISE", "FLUOR",
                  "THAL", "OUTPUT")
names(heart) = tolower(names(heart))
heart$output = heart$output - 1  

# convert output to factor
heart$output = factor(heart$output)
attach(heart)
```

### Data exploration

```{r}
str(heart)
summary(heart)
```

From the summary of the data, it is interesting to note the uneven distribution in some of the categorical variables. These include “sex”, a high amount of “chest pain” in level 4 category, only 2 “ECG” of level 1, and “thal”. Having a smaller sample space in some of these categories could negatively skew interpretations.


```{r}
par(mfrow=c(3,3))
rv = c("age", "restbp", "chol", "maxhr", "dep")
for (i in 1:5) {hist(heart[,i], main = paste("Histogram of ", rv[i]), col = 'black', xlab = rv[i])} 
pairs(heart[,rv])
cor(heart[,rv])

```

Based on previous data exploration and modelling, we are aware of the some of the variables that are significant in our model. Additionally, from the correlation matrix and plots, we see lack of issues that could arise due to co-linear variables.

```{r}
par(mfrow=c(2,3))

plot(age~chol, col = output , xlim = c(100,500), pch = 16, main = "Heart Disease: age, chol")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)


plot(age~maxhr, col = output, pch = 16, main = "Heart Disease: age ,maxhr ")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)

plot(maxhr~exercise, col = output, pch = 16, main = "Heart Disease: maxhr, exercise")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)

plot(chol~angina, col = output, pch = 16, main = "Heart Disease:chol, angina")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)

plot(maxhr~fluor, col = output, pch = 16, main = "Heart Disease: maxhr, flour")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)

plot(dep~thal, col = output, pch = 16, main = "Heart Disease:dep, thal")
legend("topleft", legend=c("HD", "no HD"), pch=16, col=output)



```

Reading top to bottom, and left to right : based on the second, fourth, and sixth plots, we can see potentially good purity levels. This will be influential in our selection criteria in our classification tree.

### Building a classification tree

From the data exploration, and the information from the previous report, the strongest model obtained will be used to build the intial classification tree. This model is : output ~ fluor + thal + chestpain + dep + maxhr + sex + angina + exercise + restbp. 

```{r}
# training and test sets
set.seed(132)
split = split_data(heart)
tr_dat = split[[1]]
te_dat = split[[2]]

fit1 = glm(output ~ fluor + thal + chestpain + dep + maxhr + sex + angina + exercise + restbp, data=tr_dat, family=binomial(link="logit"))


tree1 = rpart(fit1)
rpart.plot(tree1)

```

From this tree, it seems one of the most useful filtering criterion is "thal", since the bottom three nodes with a prediction of heart disease is predicting with probabilities close to 1. The areas of concern lie in the lack of confidence in nodes where probabilities are close to .5, or are less saturated in color, indicated not enough filtering. This shows good ability to classify extreme cases, but there still exists those who are at risk, and not correctly classified.


```{r}
gini_index = function(prob) {



  gini = 2 * prob * (1 - prob)

  return(gini)

}

gini = gini_index(as.numeric(as.data.frame(tree1[[1]]$yval2)[,6]))
gini
mean(gini)
```

The values of our gini index fair moderately successful but could be improved.

### Classifying test data

After having created the 

```{r}
y = predict(tree1, te_dat)[,2]
ytrain = predict(tree1, tr_dat)[,2]


summary(y)
hist(y, main = "Histogram of Tree's Predicted Probabilities of Heart Disease", col = 'pink', xlab = "probabilities")
```

We can see our tree is classifying with high probabilities to belonging to the binary outcomes. This indicates a high level of confidence. We must now test whether this is founded.

### Assessing the model

```{r}
predicts_tr = as.numeric(ytrain > 0.5)
actuals_tr = tr_dat$output
conf_mtxtr = table(predicts_tr, actuals_tr)

conf_mtxtr
mean(actuals_tr == predicts_tr) #accuracy



predicts = as.numeric(y > 0.5)
actuals = te_dat$output
conf_mtx = table(predicts, actuals)

conf_mtx
mean(actuals == predicts) #accuracy
```

Unsurprisingly, our classification tree performs better on our training data. What is interesting is much of the error in both training data is in false negatives. This suggests that our filtering is not as strong on individuals that are not clear risks of heart disease. This would suggest there needs to be more sensitivity in our filtering. Such suggestions would be to decrease the thresholds for "chol" or "restbp" to be classified as belonging to the group with heart disease. 



```{r}
plot(density(y[actuals == 1]), col = 'red', main = "Output of Classifier")
lines(density(y[actuals == 0]))
legend("topleft", legend=c("no heart disease", "heart disease"), pch=15, col=c('black', 'red'))
```

This density plot indicates our threshold classification is approximately correct. After also trying different threshold levels, there is no appreciable increase in accuracy. There is however, the issue of higher potentials for false positives and false negatives in future test data.

```{r}
plot(roc(actuals~y))
auc(roc(actuals~y))
```

```{r}
prec_recall_summary = function(predicts, actuals) {
   thresh = seq(0, 1, length.out=50)
   prec_rec = data.frame()
   actuals = factor(as.numeric(actuals))
   for (th in thresh) {
     predicts = factor(as.numeric(y >= th), levels=c("0","1"))
     prec_rec = rbind(prec_rec, as.vector(table(predicts, actuals)))
   }
   names(prec_rec) = c("TN", "FP", "FN", "TP")
   prec_rec$threshold = thresh
  prec_rec$precision = prec_rec$TP/(prec_rec$TP + prec_rec$FP)
   prec_rec$recall    = prec_rec$TP/(prec_rec$TP + prec_rec$FN)
   prec_rec$false_pos = prec_rec$FP/(prec_rec$FP + prec_rec$TN)
   return(prec_rec)
}

pr1 = prec_recall_summary(predicts, actuals)
attach(pr1) 
plot(precision~threshold, type = 'l')
```

Our precision increases as we increase our threshold, but this precision vs threshold graph shows no appreciable increase increasing from .5 through values up to .85. We do however, lose accuracy going to extreme.

```{r}
plot(pr.curve(predicts, actuals, curve = TRUE))
```


### Model 2

Knowing that our model with be based on a classification tree, the following model was based on the seemingly significant predictors from the previous tree "dep", "fluor", and "thal", as well as the scatter-plots from the data exploration stage that showed the predictors that had promise to produce high purity - these predictors included "age", "maxhr", "chol", "angina".

```{r}
fit2 = glm(output~maxhr+angina+chol+age+fluor+dep+thal,data=tr_dat, family=binomial(link="logit"))

tree2 = rpart(fit2)
rpart.plot(tree2)
```

This tree shows similar trends as the previous one, and actuall has less confidence in nodes. Overall this model performs worse and was not useful in mitigating the concerns of the inital model.

```{r}
y2 = predict(tree2, te_dat)[,2]
ytrain2 = predict(tree2, tr_dat)[,2]


predicts_tr2 = as.numeric(ytrain2 > 0.4)
actuals_tr2 = tr_dat$output
conf_mtxtr2 = table(predicts_tr2, actuals_tr2)

conf_mtxtr2
mean(actuals_tr2 == predicts_tr2) #accuracy



predicts2 = as.numeric(y2 > 0.42)
actuals2 = te_dat$output
conf_mtx2 = table(predicts2, actuals2)

conf_mtx2
mean(actuals2 == predicts2) #accuracy
```

This model actually obtained worse accuracy. This seems to lead to the conclusion that either not enough variables are included, or the model would generally benefit from more predictors, in the case of the ones provided in this data set. This model was based on only variables among 3 scatter plots and one classification tree. Since this model is a subset of the previous, it appears significant predictors were removed.

```{r}
gini = gini_index(as.numeric(as.data.frame(tree2[[1]]$yval2)[,6]))
gini
mean(gini)
```

There appears no appreciable improvement in the gini index.

```{r}
plot(pr.curve(predicts2, actuals2, curve = TRUE))
```


The PR curve plot seems to allow us to conclude the threshold for heart disease classification can be lowered in this model. 


```{r}
plot(roc(actuals~y2))
auc(roc(actuals~y2))
```


##Model 3

The motivations for the final model is to test if the strongest model yet achieved in logistic regression, would also produce the best fit for the classification tree. This model was the third model in the example provided in homework 12. 

```{r}
fit3 = glm(output ~ sex + chestpain + maxhr + dep + fluor + thal, data=tr_dat, family=binomial)

tree3 = rpart(fit3)
rpart.plot(tree3)

y3 = predict(tree3, te_dat)[,2]
ytrain3 = predict(tree3, tr_dat)[,2]


predicts_tr3 = as.numeric(ytrain3 > 0.5)
actuals_tr3 = tr_dat$output
conf_mtxtr3 = table(predicts_tr3, actuals_tr3)

conf_mtxtr3
mean(actuals_tr3 == predicts_tr3) #accuracy



predicts3 = as.numeric(y3 > 0.5)
actuals3 = te_dat$output
conf_mtx3 = table(predicts3, actuals3)

conf_mtx3
mean(actuals3 == predicts3) #accuracy



```

The model that generated this classification tree performs similarly to the previous trees. This indicates that changing the initial model is not neccessary, but changing the tree filtering criteria would be beneficial perhaps. Especially on the second, fourth, and fifth nodes, from the bottom (reading left to right).

```{r}
gini = gini_index(as.numeric(as.data.frame(tree3[[1]]$yval2)[,6]))
gini
mean(gini)

```

 
##Conclusions

The last model, as well as the first model, and one that includes all predictors of the data set in the model perform with an accuracy on test data of approximately 82%. This suggests a possible upper limit on the accuracy achieved through classification trees, given the variables of this data set. Providing additional parameters into rpart() could also yield better results. After having tested several options such as weights and the method type, it did not seem to yield a different tree. Further research and knowledge of the rpart package, would be needed (on my **r**part).


